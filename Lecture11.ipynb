{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:4edf940733334c44b7a9e1d66638941908984496ba512ec6f9a5ef55ac8c5d61"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "lecture = 2\n",
      "\n",
      "import sys\n",
      "sys.path.append(\"lib\")\n",
      "import fmt\n",
      "import sympy as sp\n",
      "from IPython.display import display\n",
      "\n",
      "assert sp.__version__ == \"0.7.5\", \"Need sympy version 0.7.5 to render properly\"\n",
      "sp.init_printing(use_latex = True)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Lecture 11: Numerical Methods for Ordinary Differential Equations\n",
      "\n",
      "## Topics\n",
      "\n",
      "* Introduction\n",
      "* Examples in Finance\n",
      "* Numerical Methods\n",
      "       \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Introduction\n",
      "\n",
      "\n",
      "* General **first** order ordinary differential equation (ODE) in the initial value problem (IVP) form\n",
      "\n",
      "$$\n",
      "y' = f(t,y), \\;\\; y(t_0) = y_0\n",
      "$$\n",
      "\n",
      "* The integration formulation\n",
      "\n",
      "$$\n",
      "y(t) = y_0 + \\int_{t_0}^t f(s,y(s)) \\; ds\n",
      "$$\n",
      "\n",
      "* If $f(t,y)$ is independent of $y$, solving the ODE is simply an integration. In general, the integration equation is not any easier to solve.\n",
      "\n",
      "\n",
      "* If $f(t,y)$ is independent of $t$, the ODE is said to be **autonomous**\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "* If $y$ and $f$ are vectors, this becomes a first order system of ODEs\n",
      "\n",
      "$$\n",
      "\\renewcommand{bs}{\\boldsymbol}\n",
      "\\renewcommand{by}{\\boldsymbol{y}}\n",
      "\\renewcommand{bf}{\\boldsymbol{f}}\n",
      "\\by' = \\bf(t, \\by), \\;\\; \\by(t_0) = \\by_0\n",
      "$$\n",
      "\n",
      "* General $n^{th}$ order ODE\n",
      "\n",
      "$$\n",
      "y^{(n)}(t) = f(t,y(t),y'(t), \\cdots, y^{(n-1)}(t))\n",
      "$$\n",
      "\n",
      "* It can be converted into a system of first order ODEs\n",
      "\n",
      "$$\n",
      "\\bs{z}' = \\bs{g}(t, \\bs{z})\n",
      "$$\n",
      "\n",
      "   where $\\bs{z} = (y(t),y'(t), \\cdots, y^{(n-1)})^T$ and \n",
      "\n",
      "$$\n",
      "\\begin{matrix}\n",
      "\\bs{g}(t, \\bs{z}) =  \\left[\n",
      "\\begin{matrix}\n",
      "y'(t) \\\\\n",
      "y''(t) \\\\\n",
      "\\vdots \\\\\n",
      "y^{(n-1)}(t) \\\\\n",
      "f(t,y(t),y'(t), \\cdots, y^{(n-1)}(t))\n",
      "\\end{matrix}\n",
      "\\right]\n",
      "\\end{matrix}\n",
      "$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Interesting things to know:\n",
      "\n",
      "For the general first order systems of ODE and its IVP:\n",
      "\n",
      "* Is there a solution?\n",
      "\n",
      "\n",
      "* Is the solution unique?\n",
      "\n",
      "\n",
      "* Is the solution sensitive to the data?\n",
      "\n",
      "\n",
      "* How to solve for the solution?\n",
      "\n",
      "\n",
      "\n",
      "**Theorem** (**Picard's** theorem):\n",
      "If $f(t,y)$ is Lipschitz continuous in $y$ in a neighborhood of $(t_0, y(t_0))$, then the IVP of the ODE has a uniques solution in the neighborhood.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Examples in Finance\n",
      "\n",
      "### **Black-Scholes** equation\n",
      "\n",
      "$$\n",
      "C_t = \\frac{1}{2}\\sigma^2S^2C_{SS} + rSC_S - rC\n",
      "$$\n",
      "\n",
      "Define the Laplace transform of option price function $C(t,S)$ as\n",
      "\n",
      "$$\n",
      "\\renewcommand{hC}{\\hat{C}}\n",
      "\\hC(z,\\cdot) := \\mathcal{L}[C](z) = \\int_{0}^{\\infty}C(t,\\cdot)e^{-zt} \\; dt\n",
      "$$\n",
      "\n",
      "Taking the Laplace trasform of the Black-Scholes equation,\n",
      "\n",
      "$$\n",
      "z\\hC = \\frac{1}{2}\\sigma^2S^2 \\hC_{SS} + rS \\hC_S - r \\hC + C_0\n",
      "$$\n",
      "\n",
      "Here $C_0$ is the time reversed payoff condition (*).\n",
      "\n",
      "So one way to solve Black-Scholes is to solve an ODE and then invert the Laplace Transform.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "\n",
      "### Affine Term Structure model\n",
      "\n",
      "Assume the short rate is affine under the risk-neutral measure\n",
      "$$\n",
      "dr_t = \\kappa(\\theta-r_t)dt + \\sqrt{\\sigma_1 +\\sigma_2 r_t}\\;dW_t\n",
      "$$\n",
      "\n",
      "Then bond prices are solution to the PDE:\n",
      "$$\n",
      "\\frac{1}{2}P_{rr}(\\sigma_1 +\\sigma_2 r) + P_r\\kappa(\\theta - r)+ P_t -rP = 0\n",
      "$$\n",
      "with $P(T,T) = 1$. Looking for solution in the form \n",
      "$$\n",
      "P(r,t,T) = e^{A(T-t) - B(T-t)r},\n",
      "$$\n",
      "we find that $A(\\cdot), B(\\cdot)$ solve the following system of ODE\n",
      "\n",
      "\\begin{aligned}\n",
      "-B' & = \\frac{1}{2}\\sigma_2B^2 + \\kappa B - 1\n",
      "\\\\\n",
      " A' & = \\frac{1}{2}\\sigma_1B^2 - \\kappa \\theta B\n",
      "\\end{aligned}\n",
      "with $A(0) = B(0) = 0$.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Numerical Methods \n",
      "\n",
      "* Will focus on **Finite Difference Methods**(FDM) here.\n",
      "\n",
      "\n",
      "* Other methods for ODE/PDEs: Finite element methods, Spectral Methods, etc.\n",
      "\n",
      "\n",
      "* All methods for IVP of ODE are recursions that update $y^{(k+1)}$ from previous $y^{(k)}$ together with evaluating the function $f(t, y)$ a few times around $t_k$.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "\n",
      "## Finite Difference Methods(FDM) in practice\n",
      "\n",
      "Employing finite difference method typically means:\n",
      "\n",
      "1) Generate a grid of points $(t_k, y_i)$ where we want to find the soltuions\n",
      "\n",
      "2) Substitute the derivatives in ODE/PDE with finite difference schemes, which converts the ODE/PDE into a system of algebraic equations.\n",
      "\n",
      "3) Solve the system of algebraic equations.\n",
      "\n",
      "4) Implement and debug the compute code.\n",
      "\n",
      "5) Perform sanity check, error analysis, sensitity analysis, etc, by any available means: intuitively, analytically or numerically.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## The Euler's Method \n",
      "\n",
      "* Approximate the first derivative by the forward difference formula\n",
      "$$\n",
      "\\mathcal{D}_+y(t) = \\frac{y(t+h)-y(t)}{h}  = y'(t) + O(h)\n",
      "$$\n",
      "\n",
      "* The one step (forward) Eulers method:\n",
      "$$\n",
      "\\frac{y^{n+1} - y^n}{h}  = f(t^n, y^n);\n",
      "$$\n",
      "\n",
      "* or\n",
      "\n",
      "$$\n",
      "y^{n+1} = y^n  + h f(t^n, y^n).\n",
      "$$\n",
      "\n",
      "* The method is **explicit**, we do not need to solve any equations.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## Consistency, Stability and Convergence of FDM \n",
      "\n",
      "* For any FDM that are rmployed to solve practical problems, we should ask\n",
      "\n",
      "    * 1) How acurate is the method?\n",
      "    * 2) Does it converge?\n",
      "    * 3) What is the best choice of step sizes?\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Local Truncation Error \n",
      "\n",
      "* Defined as the amount by which the exact solution does not satisfy the numerical scheme.\n",
      "\n",
      "* Just plugin the exact values of the functions/variable into the FDM scheme and calculate the error, for Euler scheme, this is,\n",
      "\n",
      "\\begin{aligned}\n",
      "\\mathcal{N}_h y(t^n) & = y(t^{n+1}) - y(t^n)  - h f(t^n, y(t^n))\n",
      "\\\\\n",
      "    & = y(t^{n}+h) - y(t^n)  - h f(t^n, y(t^n))\n",
      "\\\\\n",
      "    & = \\left( y(t^n) + hy'(t^n) + \\frac{h^2}{2}y''(t^n)+ \\cdots \\right) - y(t^n)  - h f(t^n, y(t^n))\n",
      "\\\\\n",
      "    & = \\frac{h^2}{2}y''(t^n) + O(h^3).\n",
      "\\end{aligned}\n",
      "\n",
      "   $\\\\$ where we used the exact ODE equation $y'(t^n) = f(t^n, y(t^n))$.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Consistency \n",
      "\n",
      "* An FDM is **consistent** if the local trancation error goes to 0 as the step size goes to 0.\n",
      "\n",
      "\n",
      "* An FDM is **consistent with order $q>1$** if $|\\mathcal{N}_h y(t^n) | = O(h^q)$.\n",
      "\n",
      "\n",
      "* The Euler method is consistent with the second order.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### \"Consistent Insufficiency\"\n",
      "\n",
      "* Turns out being consistent is not enough.\n",
      "\n",
      "\n",
      "* Consider the IVP of ODE\n",
      "$$\n",
      "y'(t) = \\lambda y(t), \\; y(0) = 1.0, \\; \\lambda < 0.\n",
      "$$\n",
      "\n",
      "\n",
      "* Applying the Euler method to the above gives:\n",
      "$$\n",
      "y^{n+1} = y^n + \\lambda y^n h = ( 1 + \\lambda h) y^n = ( 1 + \\lambda h)^2 y^{n-1} = \\cdots \\bs{\\leadsto}\n",
      "$$\n",
      "$$\n",
      "y^n =  ( 1 + \\lambda h)^n \n",
      "$$\n",
      "\n",
      "\n",
      "* The solution will explode if $|1+\\lambda h| > 1$. For example, when $\\lambda = -10$ and $h = 0.25$.\n",
      "\n",
      "\n",
      "* While the exact solution of the problem is $y(t) = e^{\\lambda t}$, which decays exponentially with $\\lambda <0$.\n",
      "\n",
      "\n",
      "* The problem is with error propagation of the FDM, we need more...\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Stability\n",
      "\n",
      "* We need one more property: **0-stability**\n",
      "\n",
      "\n",
      "* A method is called **zero-stable ** if there are constants $h_0$ and $K$ so for any mesh functions $y_h$ and $z_h$ on an interval $[0,T]$ with $h \\leq h_0$,\n",
      "$$\n",
      "|y^n - z^n| \\leq K\\left\\{ |y^0 - z^0| + \\max_{1 \\leq j \\leq N} | \\mathcal{N}_h y(t^j) - \\mathcal{N}_h z(t^j) | \\right\\}\n",
      "$$\n",
      "for $1 \\leq n \\leq N$.\n",
      "\n",
      "\n",
      "* Zero-stability essentially says errors (e.g. roundoff erros, function evaluation errors) introduced in any step does not get magnified later on.\n",
      "\n",
      "\n",
      "* One-step FDM can be shown to be zero-stable given sufficiently small step size and if $f$ is Lipschitz continuous in $y$.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Consistency + Stability = convergence\n",
      "\n",
      "* An FDM  is said to be **convergent with order $p > 0$ **, or to have the order of accuracy $p$, if for any finite $T$ for which the ODE has  a solution,\n",
      "\n",
      "$$\n",
      "|y^n  - y(t^n)| = O(h^p), \\;\\; \\forall 0 \\leq n \\leq T/h.\n",
      "$$\n",
      "\n",
      "\n",
      "* A central theorem in numerical method for differential equations is the **Lax equivalence theorem**: $\\hspace{4in}$\n",
      "Any consistent method is convergent if and only if it is zero-stable or\n",
      "\n",
      "$$\n",
      "\\mbox{conssistency + stability = convergence}\n",
      "$$\n",
      "\n",
      "\n",
      "* For the Euler method, the stability can be satisfied if thetime step satisfies teh **stability criterion**\n",
      "$$\n",
      "|1+\\lambda h| \\leq 1 \\Longrightarrow  0 < h < -\\frac{2}{\\lambda }.\n",
      "$$\n",
      "\n",
      "\n",
      "* This condition is often referred to as the **CFL (Courant-Fletcher-Levy)** condition.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Absolute Stability\n",
      "\n",
      "* The Euler's method is said to be **conditionally stable**.\n",
      "\n",
      "\n",
      "* Its **region of stability** is defined as the set of complex numbers $z = \\lambda h$, such that the FDM solution decays to 0.\n",
      "\n",
      "\n",
      "* For Euler's method, this is\n",
      "$$\n",
      "|1+\\lambda h| = |1+z| = |z - (-1)| \\leq 1\n",
      "$$\n",
      "which is a unit disk with radius 1 and center $(-1,0)$.\n",
      "\n",
      "\n",
      "* An FDM is called **A-Stable** or **unconditionally stable** if its region of stability is the entire negative left half plan, i.e. $\\Re{z} < 0$.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## The backward Euler's Method \n",
      "\n",
      "* The one step backward Eulers method:\n",
      "$$\n",
      "\\frac{y^{n+1} - y^n}{h}  = f(t^{n+1}, y^{n+1})\\; \\Longrightarrow \\;\n",
      "y^{n+1} = y^n  + h f(t^{n+1}, y^{n+1}).\n",
      "$$\n",
      "\n",
      "* The method is **implicit**, if $f(t,y)$ is nonlinear, we would have to solve a nonlinear equation to get $y^{n+1}$.\n",
      "\n",
      "* The local truncation error is\n",
      "\\begin{aligned}\n",
      "\\mathcal{N}_h y(t^n) & = y(t^{n+1}) - y(t^n)  - h f(t^{n+1}, y(t^{n+1}))\n",
      "\\\\\n",
      "    & = y(t^{n+1}) - y(t^{n+1}-h)  - h f(t^{n+1}, y(t^{n+1}))\n",
      "\\\\\n",
      "    & = -\\frac{h^2}{2}y''(t^{n+1}) + O(h^3).\n",
      "\\end{aligned}\n",
      "\n",
      "* Set $f(t,y) = \\lambda y$, then \n",
      "$$\n",
      "y^{n+1} = y^n + h\\lambda y^{n+1}, \\Longrightarrow y^{n+1} =\\frac{1}{1-h\\lambda}y^n\n",
      "$$\n",
      "\n",
      "* The CFL condition is $\\frac{1}{1-h\\lambda} \\leq 1$, which is always satisfied with $h > 0, \\lambda < 0$, so it is A-Stable."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## The Crank-Nicholson Method \n",
      "\n",
      "* Both Euler's method are of first order, Crank-Nicholson (also called **Trapezoidal method**) is second order:\n",
      "\n",
      "$$\n",
      "\\frac{y^{n+1} - y^n}{h}  = \\frac{1}{2}\\left( f(t^n, y^n) + f(t^{n+1}, y^{n+1}) \\right)\\; \\Longrightarrow \\;\n",
      "y^{n+1} = y^n  + \\frac{h}{2}\\left( f(t^n, y^n) + f(t^{n+1}, y^{n+1}) \\right).\n",
      "$$\n",
      "\n",
      "* The local truncation error is\n",
      "\n",
      "\\begin{aligned}\n",
      "\\mathcal{N}_h y(t^n) & = y(t^{n+1}) - y(t^n)  - \\frac{h}{2}\\left( f(t^n, y^n) + f(t^{n+1}, y^{n+1}) \\right).\n",
      "\\\\\n",
      "    & = -\\frac{h^3}{6}y'''(t^{n+1/2}) + O(h^4).\n",
      "\\end{aligned}\n",
      "\n",
      "* Set $f(t,y) = \\lambda y$,\n",
      "$$\n",
      "y^{n+1} =\\frac{1+h\\lambda}{1-h\\lambda}y^n\n",
      "$$\n",
      "\n",
      "\n",
      "* The CFL condition is $|\\frac{1+h\\lambda}{1-h\\lambda} |\\leq 1$, which is always satisfied with $h > 0, \\lambda < 0$, so it is also unconditionally stable."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "## The Runge-Kutta Method \n",
      "\n",
      "* The Crank-Nicholson method is implicit, to make it explicit, we can approximate $y^{n+1}$ in right hand side using the forward Euler's method, and this gets us to the simplest explicit Runge-Kutta method (usually called the Heun's method)\n",
      "\\begin{aligned}\n",
      "y^* & = y^n  + h f(t^n, y^n)\n",
      "\\\\\n",
      "y^{n+1} & = y^n  + \\frac{h}{2}\\left( f(t^n, y^n) + f(t^{n+1}, y^*) \\right).\n",
      "\\end{aligned}\n",
      "\n",
      "* The method is second order, but is conditionally stable.\n",
      "\n",
      "* The is a representative of a powerful class of methods called **predictor-corrector** methods: the forward Euler as the predictor and the Crank-Nicholson is the corrector."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}